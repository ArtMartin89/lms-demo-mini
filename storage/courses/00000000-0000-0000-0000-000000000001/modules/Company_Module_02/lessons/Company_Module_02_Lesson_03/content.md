# Урок 3: Оценка и валидация моделей

## Важность оценки моделей

Правильная оценка модели позволяет понять, насколько хорошо она работает и будет ли она полезна в реальных условиях.

## Метрики для классификации

### Матрица ошибок (Confusion Matrix)

Таблица, показывающая правильные и неправильные предсказания:

```
                Предсказано
              Положительно  Отрицательно
Реально  Положительно    TP         FN
         Отрицательно    FP         TN
```

где:
- **TP** (True Positive): Правильно предсказанные положительные
- **TN** (True Negative): Правильно предсказанные отрицательные
- **FP** (False Positive): Ложные срабатывания
- **FN** (False Negative): Пропущенные случаи

### Точность (Accuracy)

Доля правильных предсказаний:

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

### Точность (Precision)

Доля истинно положительных среди всех положительных:

```
Precision = TP / (TP + FP)
```

### Полнота (Recall)

Доля найденных положительных случаев:

```
Recall = TP / (TP + FN)
```

### F1-мера

Гармоническое среднее точности и полноты:

```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```

## Метрики для регрессии

### Средняя абсолютная ошибка (MAE)

```
MAE = (1/n) × Σ|y_true - y_pred|
```

### Среднеквадратичная ошибка (MSE)

```
MSE = (1/n) × Σ(y_true - y_pred)²
```

### Корень из среднеквадратичной ошибки (RMSE)

```
RMSE = √MSE
```

### Коэффициент детерминации (R²)

Показывает, насколько хорошо модель объясняет вариацию:

```
R² = 1 - (SS_res / SS_tot)
```

## Переобучение и недообучение

### Переобучение (Overfitting)

Модель слишком хорошо запоминает тренировочные данные:

- **Признаки**: Высокая точность на тренировке, низкая на тесте
- **Решение**: Регуляризация, упрощение модели, больше данных

### Недообучение (Underfitting)

Модель слишком простая:

- **Признаки**: Низкая точность на тренировке и тесте
- **Решение**: Усложнение модели, больше признаков

## Методы валидации

### Holdout

Простое разделение на train/test

### K-Fold Cross-Validation

Данные делятся на k частей:

1. Модель обучается на k-1 частях
2. Тестируется на оставшейся части
3. Процесс повторяется k раз
4. Усредняются результаты

### Stratified K-Fold

K-Fold с сохранением пропорций классов

## Регуляризация

### L1-регуляризация (Lasso)

Добавляет штраф за сумму абсолютных значений весов:

```
Loss = MSE + λ × Σ|w|
```

### L2-регуляризация (Ridge)

Добавляет штраф за сумму квадратов весов:

```
Loss = MSE + λ × Σw²
```

### Elastic Net

Комбинация L1 и L2

## Заключение

Правильная оценка и валидация моделей критически важны для создания надежных ML-систем. Используйте подходящие метрики и методы валидации для вашей задачи.

